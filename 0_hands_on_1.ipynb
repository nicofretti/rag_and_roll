{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 1: Ingestion and Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function with these requirements:​\n",
    "\n",
    "- Input: the name of the wikipedia page to ingest \"Glossary of artificial intelligence\".​\n",
    "\n",
    "- Output: list of name-description concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.schema import BaseNode\n",
    "\n",
    "def ingest_and_chunk(name_page: str) -> List[BaseNode]:\n",
    "    chunks: List[BaseNode]\n",
    "    ...\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_page = \"Glossary of artificial intelligence\" \n",
    "\n",
    "chunks = ingest_and_chunk(name_page)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(\"Number of node: \", i)\n",
    "    print(\"Text: \", chunk.text)\n",
    "    print(\"---------------\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

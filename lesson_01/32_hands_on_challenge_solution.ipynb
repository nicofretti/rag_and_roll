{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n.fretti\\Desktop\\projects\\rag_and_roll\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n.fretti\\Desktop\\projects\\rag_and_roll\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n.fretti\\Desktop\\projects\\rag_and_roll\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index>=0.11.20\n",
    "%pip install pymupdf4llm>=0.0.17\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/'\n",
    "!wget 'https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/query_engine/pdf_tables/billionaires_page.pdf?raw=true' -O 'data/billionaires_page.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from rich import print as rprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"here your openai api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./data/billionaires_page.pdf...\n",
      "[                                        ] (0/3[=                                       ] ( 1/3[==                                      ] ( 2/33[===                                     ] ( 3/3[====                                    ] ( 4/33=[======                                  ] ( 5/33[=======                                 ] ( 6/3[========                                ] ( 7/33[=========                               ] ( 8/3[==========                              ] ( 9/33=[============                            ] (10/33[=============                           ] (11/3[==============                          ] (12/33[===============                         ] (13/3[================                        ] (14/33=[==================                      ] (15/33[===================                     ] (16/3[====================                    ] (17/33[=====================                   ] (18/3=[=======================                 ] (19/3[========================                ] (20/33[=========================               ] (21/3[==========================              ] (22/33[===========================             ] (23/3=[=============================           ] (24/3[==============================          ] (25/33[===============================         ] (26/3[================================        ] (27/33[=================================       ] (28/3=[===================================     ] (29/3[====================================    ] (30/33[=====================================   ] (31/3[======================================  ] (32/33=[========================================] (33/33]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "import pathlib as pl\n",
    "md_text = pymupdf4llm.to_markdown(\"./data/billionaires_page.pdf\")\n",
    "pl.Path(\"data/output.md\").write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter, MarkdownNodeParser\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import (\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "def create_index(text_path: str) -> VectorStoreIndex:\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            MarkdownNodeParser(),\n",
    "            SentenceSplitter(\n",
    "                chunk_size=512, chunk_overlap=20\n",
    "            ),\n",
    "            KeywordExtractor(keywords=3)\n",
    "        ],\n",
    "    )\n",
    "    documents = SimpleDirectoryReader(text_path, required_exts=[\".md\"]).load_data()\n",
    "    nodes = pipeline.run(documents=documents)\n",
    "    index = VectorStoreIndex(nodes=nodes)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:14<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "index = create_index(\"data\")\n",
    "engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Elon Musk was the second richest person in the world in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Elon Musk was the second richest person in the world in \u001b[1;36m2023\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"\"\"Who was the second richest person in the world in 2023?\"\"\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">US$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">211</span> billion\n",
       "</pre>\n"
      ],
      "text/plain": [
       "US$\u001b[1;36m211\u001b[0m billion\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"\"\"What was the net worth of the richest person in 2023?\"\"\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m49\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"\"\"What was the age of the richest person in 2022?\"\"\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The primary source of wealth of the richest person in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span> was Tesla, SpaceX, and Twitter Inc.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The primary source of wealth of the richest person in \u001b[1;36m2022\u001b[0m was Tesla, SpaceX, and Twitter Inc.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"\"\"Which was the primary source of wealth of the richest person in 2022?\"\"\").response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

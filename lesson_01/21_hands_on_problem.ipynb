{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 2: Metadata & Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Problem\n",
    "\n",
    "Create a function with those requirements:​\n",
    "- ⚡ Input: path of paul_graham_essay.txt​\n",
    "- 🔄 Output: index able to answer correctly to these questions: ​\n",
    "    - \"Who is the author of the book?​\"\n",
    "    - \"What inspired the author to switch from studying philosophy to studying AI in college?​\"\n",
    "    - \"What would the author say about art vs. Engineering?​\"\n",
    "    - \"Why did the author have to learn Italian?​\"\n",
    "    - \"Why the author was in Florence?​\"\n",
    "\n",
    "### 🔍 Suggested tasks\n",
    "- 📥 Ingest text from file with the right reader​\n",
    "- 🔎 Filter useless information ​\n",
    "- ✂️ Split the page content with the best parser​\n",
    "- 📋 Extract metadata for each chunk​\n",
    "- 🏗️ Build the index​\n",
    "- ✅ Test the index on provided questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index>=0.11.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be run before any asyncio code is run\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from rich import print as rprint\n",
    "import os\n",
    "# add your imports here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"here your openai api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_index(document_path: str) -> VectorStoreIndex:\n",
    "    # add your code here...\n",
    "    # 1. create a pipeline\n",
    "    # 2. load the documents\n",
    "    # 3. run the pipeline\n",
    "    # 4. create the index\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"TODO\" \n",
    "\n",
    "index = create_index(document_path)\n",
    "\n",
    "engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(engine.query(\"Who is the author of the book?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(engine.query(\"What inspired the author to switch from studying philosophy to studying AI in college?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(engine.query(\"What would the author say about art vs. engineering?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(engine.query(\"Why did the author have to learn italian?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(engine.query(\"Why the author was in Florence?\").response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

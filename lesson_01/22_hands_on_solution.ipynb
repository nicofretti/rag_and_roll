{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 2: Metadata & Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function with these requirements:​\n",
    "\n",
    "- Input: path of paul_graham_essay.txt​\n",
    "\n",
    "- Output: index able to answer correctly to these questions: ​\n",
    "\n",
    "    - Who is the author of the book?​\n",
    "\n",
    "    - What inspired the author to switch from studying philosophy to studying AI in college?​\n",
    "\n",
    "    - What would the author say about art vs. Engineering?​\n",
    "\n",
    "    - Why did the author have to learn italian?​\n",
    "\n",
    "    - Why the author was in Florence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n.fretti\\Desktop\\projects\\rag_and_roll\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index>=0.11.20\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from rich import print as rprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"here your openai api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from llama_index.core.schema import TransformComponent\n",
    "\n",
    "\n",
    "class TextCleaner(TransformComponent):\n",
    "    def __call__(self, nodes, **kwargs):\n",
    "        for node in nodes:\n",
    "            node.text = re.sub(r\"[^0-9A-Za-z ]\", \"\", node.text)\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "def create_index(text_path: str) -> VectorStoreIndex:\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            TextCleaner(),\n",
    "            SentenceSplitter(chunk_size=512),\n",
    "            QuestionsAnsweredExtractor(questions=3)\n",
    "        ],\n",
    "    )\n",
    "    documents = SimpleDirectoryReader(text_path, required_exts=[\".txt\"]).load_data()\n",
    "    nodes = pipeline.run(documents=documents)\n",
    "    index = VectorStoreIndex(nodes=nodes)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:20<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "text_path = \"./data/\" \n",
    "\n",
    "index = create_index(text_path)\n",
    "\n",
    "engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Paul Graham\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Paul Graham\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"Who is the author of the book?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author was inspired to switch from studying philosophy to studying AI in college because they found philosophy \n",
       "courses to be boring and lacking in the depth they had expected.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author was inspired to switch from studying philosophy to studying AI in college because they found philosophy \n",
       "courses to be boring and lacking in the depth they had expected.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"What inspired the author to switch from studying philosophy to studying AI in college?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author would express a preference for pursuing art over engineering due to the longevity and independence \n",
       "associated with creating art compared to the impermanence and dependency on external factors in engineering.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author would express a preference for pursuing art over engineering due to the longevity and independence \n",
       "associated with creating art compared to the impermanence and dependency on external factors in engineering.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"What would the author say about art vs. engineering?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author had to learn Italian in order to take the entrance exam at the Accademia di Belli Arti in Florence.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author had to learn Italian in order to take the entrance exam at the Accademia di Belli Arti in Florence.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"Why did the author have to learn italian?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author was in Florence to take the entrance exam at the Accademia di Belli Arti.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author was in Florence to take the entrance exam at the Accademia di Belli Arti.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(engine.query(\"Why the author was in Florence?\").response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
